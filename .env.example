# Supabase
# Project URL: https://efyysxkdlugpnurvajhp.supabase.co
# Get your keys from: https://supabase.com/dashboard/project/efyysxkdlugpnurvajhp/settings/api
NEXT_PUBLIC_SUPABASE_URL=key_from_supabase
NEXT_PUBLIC_SUPABASE_ANON_KEY=key_from_supabase
SUPABASE_SERVICE_ROLE_KEY=key_from_supabase

# LLM Provider - OpenAI (recommended)
#OPENAI_API_KEY=get_from_openai
OPENAI_MODEL=gpt-4o-mini

# Embeddings Provider - OpenAI (RECOMMENDED)
# Why OpenAI embeddings? Since you're using OpenAI for LLM, using their embeddings provides:
# - Best integration and consistency
# - Excellent quality (text-embedding-3-small is fast and accurate)
# - Cost-effective ($0.02 per 1M tokens)
# - Same API key works for both LLM and embeddings
# Alternative options: Cohere (good quality), Voyage AI (specialized for RAG)
OPENAI_EMBEDDINGS_MODEL=text-embedding-3-small
# Use the same OPENAI_API_KEY for embeddings (no separate key needed)

# Re-ranking Configuration (Phase 12.1)
# Re-ranking improves search result quality by re-scoring candidates using semantic similarity
# and optionally applying diversity (MMR) to avoid redundant results
# Default: disabled (set to 'true' to enable)
ENABLE_RERANKING=false
# Number of candidates to re-rank (typically 20-50, default: 30)
# Higher values = better quality but slower performance
RERANKING_TOP_K_CANDIDATES=30
# Number of final results after re-ranking (default: 8)
RERANKING_TOP_K_RESULTS=8
# Enable Maximal Marginal Relevance (MMR) for diversity
# MMR balances relevance with diversity to avoid returning similar chunks
# Default: disabled (set to 'true' to enable)
ENABLE_MMR=false
# MMR lambda parameter (0-1): 0 = pure relevance, 1 = pure diversity
# Recommended: 0.5 for balanced approach
MMR_LAMBDA=0.5

# Sentry (optional)
NEXT_PUBLIC_SENTRY_DSN=your_sentry_dsn

# Agent/Orchestrator
DEFAULT_TENANT_ID=default-tenant

# Environment
NODE_ENV=development

